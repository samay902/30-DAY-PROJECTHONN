{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "data=pd.read_csv(\"housing.csv\",names=column_names,delimiter=r\"\\s+\")#r\"\\s+\" means split and arrange the data wherever theres tabs, space \n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "print(data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "fig,axs=plt.subplots(ncols=7,nrows=2, figsize=(20,10))\n",
    "index=0\n",
    "axs=axs.flatten()\n",
    "for k,v in data.items():\n",
    "    sns.boxplot(y=k,data=data,ax=axs[index])\n",
    "    index+=1\n",
    "plt.tight_layout(pad=0.4,w_pad=0.5,h_pad=5.0)#observation of the data spreadings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in data.items():\n",
    "    q1=v.quantile(0.25)\n",
    "    q3=v.quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "    v_col = v[(v <= q1 - 1.5 * iqr) | (v >= q3 + 1.5 * iqr)]#takes the data inside the upper and lower threshold (outliers gone)\n",
    "    perc = np.shape(v_col)[0] * 100.0 / np.shape(data)[0]\n",
    "    print(\"Column %s outliers = %.2f%%\" % (k, perc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in data.items():\n",
    "    sns.histplot(v,ax=axs[index])\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)#histogram for the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~(data['MEDV'] >= 50.0)]\n",
    "print(np.shape(data))#removal of the outliers of the target function bc sometimes the house may be unusually expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(data.corr().abs(),  annot=True)#.abs() to only get the value above 0 bc corr is range(-1 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#compare each feat with the target feature i.e MEDV\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "column_sels=['LSTAT', 'INDUS', 'NOX', 'PTRATIO', 'RM', 'TAX', 'DIS', 'AGE']\n",
    "x = data.loc[:,column_sels]#to remove the name of the name of features as loc accesses the row and columns\n",
    "y=data['MEDV']\n",
    "X=pd.DataFrame(data=min_max_scaler.fit_transform(x),columns=column_sels)\n",
    "fig, axs = plt.subplots(ncols=4, nrows=2, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for i, k in enumerate(column_sels):\n",
    "    sns.regplot(y=y, x=x[k], ax=axs[i])\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_y=np.log1(y)\n",
    "for  col in x.columns():#iterate through all x cols for skewness search\n",
    "    if np.abs(x[col].skew() > 0.3):#threshold is 0.3 for skewness of column\n",
    "        x[col]=np.log1(x[col])#reduce skewness by implementing log trans (add 1 for convinience)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model,datasets\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "l_regr=linear_model.LinearRegression()\n",
    "Kf=KFold(n_splits=10)#does cross vali\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "x_scaled=min_max_scaler.fit_transform(x)\n",
    "scores=cross_val_score(l_regr,x_scaled,y,cv=Kf,scoring=\"neg_mean_squared_error\")\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_map={}\n",
    "scores_map[\"LinearRegression\"]=scores\n",
    "l_ridge=linear_model.Ridge()\n",
    "scores=cross_val_score(l_ridge,x_scaled,y,cv=Kf,scoring=\"neg_mean_squared_error\")\n",
    "scores[\"Ridge\"]=scores\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "for degree in range(2, 6):\n",
    "   model = make_pipeline(PolynomialFeatures(degree=degree), linear_model.Ridge())\n",
    "   scores = cross_val_score(model, x_scaled, y, cv=Kf, scoring='neg_mean_squared_error')\n",
    "   print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "   #leave the degree selection logic for tmrw\n",
    "   model=make_pipeline(PolynomialFeatures(degree=3),linear_model.Ridge())\n",
    "   scores=cross_val_score(model,x_scaled,y,cv=Kf,scoring=\"neg_mean_squared_error\")\n",
    "   print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "      \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1) #rbf changes the dimensional_space of the data to find pattern\n",
    "#grid_sv = GridSearchCV(svr_rbf, cv=kf, param_grid={\"C\": [1e0, 1e1, 1e2, 1e3], \"gamma\": np.logspace(-2, 2, 5)}, scoring='neg_mean_squared_error')\n",
    "#grid_sv.fit(x_scaled, y)\n",
    "#print(\"Best classifier :\", grid_sv.best_estimator_)\n",
    "scores = cross_val_score(svr_rbf, x_scaled, y, cv=Kf, scoring='neg_mean_squared_error')\n",
    "scores_map['SVR'] = scores\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "desc_tr=DecisionTreeRegressor(max_depth=5)\n",
    "scores=cross_val_score(desc_tr,x_scaled,y,cv=Kf,scoring=\"neg_mean_squared_error\")\n",
    "scores_map[DecisionTreeRegressor]=scores\n",
    "print(\"MSE : %0.2f(+/- %0.2f )\" % (scores.mean(),scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn=KNeighborsRegressor(n_neighbors=7)\n",
    "scores=cross_val_score(knn,x_scaled,y,cv=Kf,scoring=\"neg_mean_sqaured_error\")\n",
    "scores_map[\"KNeighborsRegressor\"]=scores#acts as a container for having scores of different algo for ensemble to select\n",
    "print(\"MSE : %0.2f (+/- %0.2f ) \" %(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "grb = GradientBoostingRegressor(alpha=0.9,learning_rate=0.05, max_depth=2, min_samples_leaf=5, min_samples_split=2, n_estimators=100, random_state=30)\n",
    "scores=cross_val_score(grb,x_scaled,y,cv=Kf,scoring=\"neg_mean_squared_error\")\n",
    "scores_map[\"GradientBoostingRegressor\"]=scores\n",
    "print(\"MSE : %0.2f (+/- %0.2f)\" % (scores.mean(),scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now finally the display \n",
    "plt.figure(figsize=(20,10))\n",
    "scores_map=pd.DataFrame(scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "~samay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
