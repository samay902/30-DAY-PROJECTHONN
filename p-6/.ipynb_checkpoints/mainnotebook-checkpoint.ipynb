{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_housing_data():\n",
    "    tarball_path = Path(\"numpyex/housing.tgz\")\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"numpyex\").mkdir(parents=True, exist_ok=True)\n",
    "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "        with tarfile.open(tarball_path) as housing_tarball:\n",
    "            housing_tarball.extractall(path=\"numpyex\")\n",
    "    return pd.read_csv(Path(\"numpyex/housing/housing.csv\"))\n",
    "house=load_housing_data()\n",
    "house.head()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "house.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "house.hist(bins=46,figsize=(12,10))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(house, test_size=0.2)\n",
    "train.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "house[\"med_inc_cat\"] = pd.cut(house[\"median_income\"], bins=[0, 1, 3, 4, 6, np.inf], labels=[1, 2, 3, 4, 5])",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "house[\"med_inc_cat\"].value_counts().sort_index().plot.bar(rot=0, figsize=(12,10),grid=True)\n",
    "plt.title(\"Median Income\")\n",
    "plt.xlabel(\"income\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "strat_train_set, strat_test_set = train_test_split(\n",
    "house, test_size=0.2, stratify=house[\"med_inc_cat\"], random_state=42)\n",
    "strat_test_set[\"med_inc_cat\"].value_counts() / len(strat_test_set)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "strat_train_set.copy()\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "house.plot(kind=\"scatter\",x=\"longitude\",y=\"latitude\",grid=\"True\",alpha=0.2)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "house.plot(kind=\"scatter\",x=\"longitude\",y=\"latitude\",grid=\"True\",s=(house[\"population\"])/1000,c=house[\"median_house_value\"],cmap=\"jet\",colorbar=True,legend=True\n",
    ",figsize=(12,10))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "house[\"med_inc_c\"] = pd.cut(house[\"median_income\"], bins=[0, 1, 3, 4, 6, np.inf], labels=[1, 2, 3, 4, 5])\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "attributes=[\"median_house_value\",\"population\",\"median_income\",\"total_rooms\",\"latitude\",\"longitude\"]\n",
    "scatter_matrix(house[attributes],figsize=(12,10))\n",
    "                                               \n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "house.plot(kind=\"scatter\",x=\"median_income\",y=\"median_house_value\",alpha=0.2,grid=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "house.plot(kind=\"scatter\",x=\"housing_median_age\",y=\"median_house_value\",alpha=0.2,grid=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "house.plot(kind=\"scatter\",x=\"housing_median_age\",y=\"population\",alpha=0.2,grid=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "housing_labels=strat_train_set[\"median_house_value\"].copy()#separating the labels and the predictors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer( strategy='median')\n",
    "housing_num=house.select_dtypes(include=[np.number])\n",
    "imputer.fit(housing_num)\n",
    "imputer.statistics_\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X=imputer.transform(housing_num)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#as imputing changes the dataset into a array so it needs to be again changed into a data frame with features and labels\n",
    "house_df=pd.DataFrame(X,columns=housing_num.columns,index=housing_num.index)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "housing_head=house[[\"ocean_proximity\"]]\n",
    "housing_head.head(10)\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder=OrdinalEncoder()\n",
    "encoded_op=encoder.fit_transform(housing_head)\n",
    "print(encoder.categories_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder_oh=OneHotEncoder()\n",
    "encoded_oh=encoder_oh.fit_transform(housing_head)\n",
    "print(encoded_oh.toarray())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_test=pd.DataFrame({\"ocean_proximity\" : [\"INLAND\",\"NEAR BAY\"]} )\n",
    "print(pd.get_dummies(df_test))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_unknown_test=pd.DataFrame({\"ocean_proximity\" : [\"ISLAND\",\"NEAR OCEAN\"]} )\n",
    "print(pd.get_dummies(df_unknown_test))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder=OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "\n",
    "encoded_oh=encoder.fit_transform(df_unknown_test)\n",
    "print(encoded_oh.toarray())\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(encoder.feature_names_in_)\n",
    "print(encoder.get_feature_names_out())\n",
    "print(encoder.transform(df_unknown_test).shape)\n",
    "print(len(encoder.get_feature_names_out()))   \n",
    "\n",
    "print(encoder.transform(df_unknown_test).shape)  # Actual transformed shape\n",
    "print(len(encoder.get_feature_names_out()))      # Expected number of columns\n",
    "print(encoder.categories_)  # Categories learned during training\n",
    "print(df_unknown_test.head())\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "cat_pipeline=make_pipeline(SimpleImputer(strategy=\"most_frequent\"),OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ratio(X):\n",
    "    return X[:,[0]]/X[:,[1]]\n",
    "def ratio_name(feature_transformer,features_names_in):\n",
    "    return ['ratio']\n",
    "\n",
    "def ratio_pipeline():\n",
    "    return make_pipeline(SimpleImputer(strategy=\"median\"),FunctionTransformer(ratio,feature_names_out=ratio_name),StandardScaler())\n",
    "log_pipeline=make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    FunctionTransformer(np.log,feature_names_out=\"one-to-one\")\n",
    ")\n",
    "cluster_simil=KMeans(n_clusters=10,n_init=10,random_state=100)\n",
    "default_num_pipeline=make_pipeline(SimpleImputer(strategy=\"median\"),StandardScaler())\n",
    "custom_trans=ColumnTransformer([\n",
    "    (\"pop_per_house\",ratio_pipeline(),[\"population\",\"households\"]),\n",
    "    (\"rooms_per_house\",ratio_pipeline(),[\"total_rooms\",\"households\"]),\n",
    "    (\"bedroom_per_room\",ratio_pipeline(),[\"total_bedrooms\",\"total_rooms\"]),\n",
    "    (\"log\",log_pipeline,[\"total_rooms\",\"total_bedrooms\",\"median_income\",\"population\"]),\n",
    "    (\"geographical\",cluster_simil,[\"longitude\",\"latitude\"]),\n",
    "    (\"cat\",cat_pipeline,make_column_selector(dtype_include=\"object\")),\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "],\n",
    "   remainder=default_num_pipeline)\n",
    "house_prepared=custom_trans.fit_transform(house)\n",
    "print(house_prepared.shape)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T12:26:38.058606Z",
     "start_time": "2025-02-05T12:26:36.120799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg=make_pipeline(custom_trans,LinearRegression())\n",
    "\n",
    "\n",
    "\n",
    "lin_reg.fit(house, housing_labels)\n",
    "\n",
    "# Predict and print results\n",
    "predictions = lin_reg.predict(house)\n",
    "print(predictions[:5].round(-2))\n",
    "\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinear_model\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LinearRegression\n\u001B[1;32m----> 2\u001B[0m lin_reg\u001B[38;5;241m=\u001B[39m\u001B[43mmake_pipeline\u001B[49m(custom_trans,LinearRegression())\n\u001B[0;32m      6\u001B[0m lin_reg\u001B[38;5;241m.\u001B[39mfit(house, housing_labels)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Predict and print results\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'make_pipeline' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "~samay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
